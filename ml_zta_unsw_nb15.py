"""ML_ZTA_UNSW-NB15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y36zvW5zPulZm2CxdQqHDKIsdQ_NaStL

# ML-Enhanced Zero-Trust Architecture
## Hybrid Random Forest + Autoencoder Model
### Jack Steele (24533489)

**This notebook supports:**
- ✅ Synthetic data (default - no download needed)
- ✅ UNSW-NB15 dataset (upload CSV file)
- ✅ CICIDS2017 dataset (upload CSV file)

**Instructions:**
1. If using UNSW-NB15 or CICIDS2017, upload CSV file first (Files icon → Upload)
2. Change DATASET_TYPE in configuration cell below
3. Click `Runtime` → `Run all`
4. Download results from Files tab

**Output Files:**
- `performance_results.csv` - Performance comparison table
- `confusion_matrix.png` - Confusion matrix visualization
- `roc_curves.png` - ROC curves for all models

"""

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================

# Choose: 'synthetic', 'unsw-nb15', or 'cicids2017'
DATASET_TYPE = 'unsw-nb15'

DATASET_PATH = 'UNSW-NB15_1.csv'

# Number of samples for synthetic data
N_SAMPLES = 10000

print(f"Configuration: {DATASET_TYPE}")
if DATASET_TYPE != 'synthetic':
    print(f"Dataset file: {DATASET_PATH}")

"""
Import Libraries
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
import matplotlib.pyplot as plt

print("✓ Libraries imported")

"""
Data Preprocessing Class
"""

class DataPreprocessor:
    def __init__(self):
        self.scaler = StandardScaler()
        self.selected_features = None

    def generate_data(self, n_samples=10000):
        print(f"\nGenerating {n_samples} synthetic samples...")
        np.random.seed(42)
        n_normal = int(n_samples * 0.7)
        n_attack = n_samples - n_normal

        normal = pd.DataFrame({
            'dur': np.random.exponential(2, n_normal),
            'spkts': np.random.poisson(50, n_normal),
            'dpkts': np.random.poisson(45, n_normal),
            'sbytes': np.random.lognormal(8, 1.5, n_normal),
            'dbytes': np.random.lognormal(7.8, 1.5, n_normal),
            'rate': np.random.gamma(2, 10, n_normal),
            'sload': np.random.gamma(1.5, 100, n_normal),
            'dload': np.random.gamma(1.5, 95, n_normal),
            'sloss': np.random.poisson(0.5, n_normal),
            'dloss': np.random.poisson(0.5, n_normal),
            'label': 0
        })

        attack = pd.DataFrame({
            'dur': np.random.exponential(0.5, n_attack),
            'spkts': np.random.poisson(200, n_attack),
            'dpkts': np.random.poisson(5, n_attack),
            'sbytes': np.random.lognormal(10, 2, n_attack),
            'dbytes': np.random.lognormal(6, 2, n_attack),
            'rate': np.random.gamma(5, 50, n_attack),
            'sload': np.random.gamma(3, 200, n_attack),
            'dload': np.random.gamma(1, 50, n_attack),
            'sloss': np.random.poisson(5, n_attack),
            'dloss': np.random.poisson(5, n_attack),
            'label': 1
        })

        df = pd.concat([normal, attack]).sample(frac=1, random_state=42).reset_index(drop=True)
        print(f"✓ Generated {len(df)} samples (Normal: {n_normal}, Attack: {n_attack})")
        return df

    def select_features(self, X, y, n_features=10):
        print(f"\nSelecting top {n_features} features...")
        rf = RandomForestClassifier(n_estimators=50, random_state=42)
        rf.fit(X, y)

        importance = pd.DataFrame({
            'feature': X.columns,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)

        self.selected_features = importance.head(n_features)['feature'].tolist()
        print(f"✓ Selected: {self.selected_features[:5]}...")
        return X[self.selected_features]

    def preprocess(self, df, n_features=10):
        print("\nPreprocessing...")
        y = df['label'].values
        X = df.drop('label', axis=1)

        X = self.select_features(X, y, n_features=n_features)

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )

        X_train = self.scaler.fit_transform(X_train)
        X_test = self.scaler.transform(X_test)

        print(f"✓ Training: {X_train.shape}, Testing: {X_test.shape}")
        return X_train, X_test, y_train, y_test

print("✓ DataPreprocessor loaded")

"""
Model Classes
"""

class RandomForestModel:
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)

    def train(self, X_train, y_train):
        self.model.fit(X_train, y_train)

    def predict(self, X):
        return self.model.predict(X)

    def predict_proba(self, X):
        return self.model.predict_proba(X)[:, 1]

    def evaluate(self, X_test, y_test):
        predictions = self.predict(X_test)
        return {
            'accuracy': accuracy_score(y_test, predictions),
            'precision': precision_score(y_test, predictions, zero_division=0),
            'recall': recall_score(y_test, predictions, zero_division=0),
            'f1_score': f1_score(y_test, predictions, zero_division=0)
        }

class AutoencoderModel:
    def __init__(self, input_dim):
        self.model = MLPRegressor(
            hidden_layer_sizes=(64, 32, 64),
            max_iter=100,
            random_state=42
        )
        self.threshold = None

    def train(self, X_normal):
        self.model.fit(X_normal, X_normal)

    def reconstruction_error(self, X):
        reconstructed = self.model.predict(X)
        return np.mean((X - reconstructed) ** 2, axis=1)

    def set_threshold(self, X_normal, percentile=95):
        errors = self.reconstruction_error(X_normal)
        self.threshold = np.percentile(errors, percentile)

    def predict(self, X):
        errors = self.reconstruction_error(X)
        return (errors > self.threshold).astype(int)

    def get_anomaly_scores(self, X):
        errors = self.reconstruction_error(X)
        return (errors - errors.min()) / (errors.max() - errors.min() + 1e-10)

    def evaluate(self, X_test, y_test):
        predictions = self.predict(X_test)
        return {
            'accuracy': accuracy_score(y_test, predictions),
            'precision': precision_score(y_test, predictions, zero_division=0),
            'recall': recall_score(y_test, predictions, zero_division=0),
            'f1_score': f1_score(y_test, predictions, zero_division=0)
        }

class HybridModel:
    def __init__(self, rf_weight=0.6, ae_weight=0.4):
        self.rf_weight = rf_weight
        self.ae_weight = ae_weight
        self.rf = None
        self.ae = None

    def train(self, X_train, y_train):
        self.rf = RandomForestModel()
        self.rf.train(X_train, y_train)

        X_train_normal = X_train[y_train == 0]
        self.ae = AutoencoderModel(input_dim=X_train.shape[1])
        self.ae.train(X_train_normal)
        self.ae.set_threshold(X_train_normal)

    def predict_threat_score(self, X):
        rf_score = self.rf.predict_proba(X)
        ae_score = self.ae.get_anomaly_scores(X)
        return (self.rf_weight * rf_score) + (self.ae_weight * ae_score)

    def predict(self, X, threshold=0.5):
        threat_scores = self.predict_threat_score(X)
        return (threat_scores > threshold).astype(int)

    def evaluate(self, X_test, y_test):
        predictions = self.predict(X_test)
        return {
            'accuracy': accuracy_score(y_test, predictions),
            'precision': precision_score(y_test, predictions, zero_division=0),
            'recall': recall_score(y_test, predictions, zero_division=0),
            'f1_score': f1_score(y_test, predictions, zero_division=0)
        }

print("✓ Model classes loaded")

"""
Load Data
"""

print("="*70)
print("LOADING DATA")
print("="*70)

prep = DataPreprocessor()

if DATASET_TYPE == 'synthetic':
    df = prep.generate_data(N_SAMPLES)

elif DATASET_TYPE == 'unsw-nb15':
    print(f"\nLoading UNSW-NB15 from {DATASET_PATH}...")

    column_names = [
        'srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur', 'sbytes', 'dbytes',
        'sttl', 'dttl', 'sloss', 'dloss', 'service', 'sload', 'dload', 'spkts', 'dpkts',
        'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len',
        'sjit', 'djit', 'stime', 'ltime', 'sintpkt', 'dintpkt', 'tcprtt', 'synack',
        'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login',
        'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm',
        'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'label'
    ]

    df = pd.read_csv(DATASET_PATH, names=column_names, header=None, low_memory=False)
    df['label'] = df['label'].astype(int)

    cols_to_drop = ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'service', 'attack_cat']
    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns], errors='ignore')
    df = df.select_dtypes(include=[np.number])
    df = df.replace([np.inf, -np.inf], np.nan).dropna()

    print(f"✓ Loaded {len(df)} samples (Normal: {sum(df['label']==0)}, Attack: {sum(df['label']==1)})")

elif DATASET_TYPE == 'cicids2017':
    print(f"\nLoading CICIDS2017 from {DATASET_PATH}...")
    df = pd.read_csv(DATASET_PATH)

    label_col = ' Label' if ' Label' in df.columns else 'Label'
    df['label'] = df[label_col].apply(lambda x: 0 if x == 'BENIGN' else 1)
    df = df.drop(label_col, axis=1)

    df = df.select_dtypes(include=[np.number])
    df = df.replace([np.inf, -np.inf], np.nan).dropna()

    print(f"✓ Loaded {len(df)} samples (Normal: {sum(df['label']==0)}, Attack: {sum(df['label']==1)})")

else:
    raise ValueError(f"Unknown dataset type: {DATASET_TYPE}")

print("\n" + "="*70)

"""
Preprocess Data
"""

X_train, X_test, y_train, y_test = prep.preprocess(df, n_features=10)
print("\n✓ Data ready for training")

"""
Train Models
"""

print("\n" + "="*70)
print("TRAINING MODELS")
print("="*70)

print("\n1. Training Random Forest...")
rf = RandomForestModel()
rf.train(X_train, y_train)
print("   ✓ Complete")

print("\n2. Training Autoencoder...")
X_train_normal = X_train[y_train == 0]
ae = AutoencoderModel(input_dim=X_train.shape[1])
ae.train(X_train_normal)
ae.set_threshold(X_train_normal)
print("   ✓ Complete")

print("\n3. Training Hybrid Model...")
hybrid = HybridModel(rf_weight=0.6, ae_weight=0.4)
hybrid.train(X_train, y_train)
print("   ✓ Complete")

print("\n" + "="*70)

"""
Evaluate and Compare
"""

rf_metrics = rf.evaluate(X_test, y_test)
ae_metrics = ae.evaluate(X_test, y_test)
hybrid_metrics = hybrid.evaluate(X_test, y_test)

results = pd.DataFrame({
    'Model': ['Random Forest', 'Autoencoder', 'Hybrid (RF+AE)'],
    'Accuracy': [rf_metrics['accuracy'], ae_metrics['accuracy'], hybrid_metrics['accuracy']],
    'Precision': [rf_metrics['precision'], ae_metrics['precision'], hybrid_metrics['precision']],
    'Recall': [rf_metrics['recall'], ae_metrics['recall'], hybrid_metrics['recall']],
    'F1-Score': [rf_metrics['f1_score'], ae_metrics['f1_score'], hybrid_metrics['f1_score']]
})

print("\n" + "="*70)
print(f"PERFORMANCE COMPARISON - {DATASET_TYPE.upper()}")
print("="*70)
print(results.to_string(index=False))
print("="*70)

results.to_csv('performance_results.csv', index=False)
print("\n✓ Saved to performance_results.csv")

"""
Generate Visualisations
"""

# Confusion Matrix
hybrid_pred = hybrid.predict(X_test)
cm = confusion_matrix(y_test, hybrid_pred)

plt.figure(figsize=(8, 6))
ConfusionMatrixDisplay(cm, display_labels=['Normal', 'Attack']).plot(cmap='Blues')
plt.title(f'Hybrid Model - {DATASET_TYPE.upper()}', fontsize=14, fontweight='bold')
plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')
plt.show()
print("✓ Saved confusion_matrix.png")

# ROC Curves
plt.figure(figsize=(10, 8))

rf_proba = rf.predict_proba(X_test)
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_proba)
auc_rf = auc(fpr_rf, tpr_rf)
plt.plot(fpr_rf, tpr_rf, label=f'RF (AUC={auc_rf:.3f})', linewidth=2.5)

ae_scores = ae.get_anomaly_scores(X_test)
fpr_ae, tpr_ae, _ = roc_curve(y_test, ae_scores)
auc_ae = auc(fpr_ae, tpr_ae)
plt.plot(fpr_ae, tpr_ae, label=f'AE (AUC={auc_ae:.3f})', linewidth=2.5)

hybrid_scores = hybrid.predict_threat_score(X_test)
fpr_h, tpr_h, _ = roc_curve(y_test, hybrid_scores)
auc_h = auc(fpr_h, tpr_h)
plt.plot(fpr_h, tpr_h, label=f'Hybrid (AUC={auc_h:.3f})', linewidth=2.5, color='red')

plt.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1.5)
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title(f'ROC Curves - {DATASET_TYPE.upper()}', fontsize=14, fontweight='bold')
plt.legend(loc='lower right', fontsize=11)
plt.grid(alpha=0.3)
plt.savefig('roc_curves.png', dpi=150, bbox_inches='tight')
plt.show()
print("✓ Saved roc_curves.png")

"""
Sample ZTA Decisions
"""

print("\n" + "="*70)
print("SAMPLE ZTA DECISIONS (First 10)")
print("="*70)

scores = hybrid.predict_threat_score(X_test[:10])
for i, (score, actual) in enumerate(zip(scores, y_test[:10])):
    if score < 0.3:
        decision, trust = "GRANT", "High"
    elif score < 0.5:
        decision, trust = "MONITOR", "Medium"
    elif score < 0.8:
        decision, trust = "RE-AUTH", "Low"
    else:
        decision, trust = "DENY", "None"

    actual_label = "Attack" if actual == 1 else "Normal"
    correct = "✓" if (score > 0.5 and actual == 1) or (score <= 0.5 and actual == 0) else "✗"

    print(f"\n{i+1}. Score: {score:.3f} → {decision} ({trust} Trust) | Actual: {actual_label} {correct}")

print("\n" + "="*70)
